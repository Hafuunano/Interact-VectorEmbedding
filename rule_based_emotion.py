"""

Reference From : https://github.com/NickCharlie/astrbot_plugin_self_learning/

"""

from __future__ import annotations

import re
from typing import NamedTuple

try:
    from config import EMOTION_LABELS
except ImportError:
    EMOTION_LABELS = ["å¼€å¿ƒ", "æ‚²ä¼¤", "æ„¤æ€’", "æƒŠè®¶", "ææƒ§", "åŽŒæ¶", "ä¸­æ€§"]


class RuleBasedEmotionResult(NamedTuple):
    """Same shape as EmotionResult for compatibility."""
    emotion: str
    score: float
    scores: dict[str, float] | None = None  # optional: all category scores


# Keyword lists per emotion (Chinese + common emoji). Order matches EMOTION_LABELS usage.
EMOTION_KEYWORDS: dict[str, list[str]] = {
    "å¼€å¿ƒ": [
        "å¼€å¿ƒ", "é«˜å…´", "å…´å¥‹", "æ»¡æ„", "å–œæ¬¢", "çˆ±", "å¥½æ£’", "å¤ªå¥½äº†", "å“ˆå“ˆ",
        "å¿«ä¹", "æ„‰å¿«", "å¹¸ç¦", "èµž", "æ£’", "è°¢è°¢", "ðŸ˜„", "ðŸ˜Š", "ðŸ‘", "â¤ï¸",
    ],
    "æ‚²ä¼¤": [
        "éš¾è¿‡", "ä¼¤å¿ƒ", "æ‚²å“€", "æ²®ä¸§", "éƒé—·", "å“­", "ç—›è‹¦", "å¤±è½", "å¤±æœ›",
        "ðŸ˜­", "ðŸ˜¢", "ðŸ’”",
    ],
    "æ„¤æ€’": [
        "ç”Ÿæ°”", "æ„¤æ€’", "çƒ¦", "è®¨åŽŒ", "ç«å¤§", "æ°”", "æ¼ç«", "æš´èº",
        "ðŸ˜¡",
    ],
    "æƒŠè®¶": [
        "å“‡", "å¤©å“ª", "çœŸçš„", "ä¸ä¼šå§", "ç«Ÿç„¶", "å±…ç„¶", "æƒŠ", "å“",
        "ðŸ˜±", "ðŸ˜¯", "ðŸ¤”",
    ],
    "ææƒ§": [
        "å®³æ€•", "ææƒ§", "æ…Œ", "å“", "ææ€–", "æ‹…å¿ƒ", "ä¸å®‰", "ç´§å¼ ",
    ],
    "åŽŒæ¶": [
        "æ¶å¿ƒ", "å«Œå¼ƒ", "åæ„Ÿ", "è®¨åŽŒ", "çƒ¦", "ç³Ÿç³•", "å·®", "ä¸è¡Œ",
        "å", "çƒ‚", "ç³Ÿ", "å±Ž", "æ»š", "å‘¸",
    ],
    "ä¸­æ€§": [
        "çŸ¥é“", "æ˜Žç™½", "å¯ä»¥", "å¥½çš„", "å—¯", "å“¦", "è¿™æ ·", "ç„¶åŽ",
        "å—", "å‘¢", "ä»€ä¹ˆ", "æ€Žä¹ˆ", "ä¸ºä»€ä¹ˆ", "å“ªé‡Œ",
    ],
}


def _tokenize(text: str) -> list[str]:
    """Split text by spaces and common Chinese punctuation; filter empty. No embedding."""
    if not text or not text.strip():
        return []
    # Same pattern as astrbot: spaces + ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š
    parts = re.split(r"\s+|[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€]", text.strip())
    return [p for p in parts if p]


def classify_rule_based(text: str) -> RuleBasedEmotionResult:
    """
    Classify text into one emotion by keyword matching only (no LLM, no embedding).
    Returns the emotion with highest score and that score; optionally all scores in result.
    """
    words = _tokenize(text)
    total = max(len(words), 1)

    # Build score per label (only for labels we have keywords for)
    labels = [lab for lab in EMOTION_LABELS if lab in EMOTION_KEYWORDS]
    if not labels:
        labels = list(EMOTION_KEYWORDS.keys())

    scores_dict: dict[str, float] = {}
    for label in labels:
        keywords = EMOTION_KEYWORDS.get(label, [])
        count = sum(1 for w in words if w in keywords)
        scores_dict[label] = count / total

    if not scores_dict:
        default = EMOTION_LABELS[-1] if EMOTION_LABELS else "ä¸­æ€§"
        return RuleBasedEmotionResult(emotion=default, score=0.0, scores=None)

    best_label = max(scores_dict, key=scores_dict.get)
    best_score = scores_dict[best_label]

    # When no keyword matched (all zeros), return neutral instead of first label (e.g. å¼€å¿ƒ)
    if best_score <= 0.0:
        neutral = "ä¸­æ€§"
        if neutral in EMOTION_LABELS:
            best_label = neutral
        else:
            best_label = EMOTION_LABELS[-1] if EMOTION_LABELS else "ä¸­æ€§"

    return RuleBasedEmotionResult(
        emotion=best_label,
        score=best_score,
        scores=scores_dict,
    )


def is_available() -> bool:
    """Rule-based path is always available (no model load)."""
    return True
